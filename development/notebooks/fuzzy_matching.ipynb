{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import re # use regular expression (regex) operations on top of fuzzscore\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from names_matcher import NamesMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy vs Names Matching vs Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity function\n",
    "\n",
    "def compare_cosine_similarity(product1, product2):\n",
    "    names = [product1, product2]\n",
    "    # create the document term matrix\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    sparse_matrix = count_vectorizer.fit_transform(names)\n",
    "    \n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names_out(), \n",
    "                  index=['name1', 'name2'])\n",
    "    result = cosine_similarity(df, df)\n",
    "    return result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSITIVE SAMPLE\n",
    "# sample 1 - products that can/should be matched\n",
    "bbw_1 = \"BODEGAS VALDUERO 6 AÑOS RESERVA PREMIUM 2015\"\n",
    "comp_1 = \"Bodegas Valduero Ribera Del Duero Reserva Premium 6 Anos\"\n",
    "comp_2 = \"Ribera Del Duero 6 Años Reserva Premium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity result\n",
      "0.5773502691896258\n",
      "0.5000000000000001\n",
      "Names matcher result\n",
      "1.0\n",
      "1.0\n",
      "Fuzzy ratio result\n",
      "0.22\n",
      "0.27\n",
      "Fuzzy ratio result - considering case sensitivity\n",
      "0.72\n",
      "0.8\n",
      "Fuzzy token sort ratio result - token set is not case sensitive\n",
      "0.88\n",
      "0.74\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity result\n",
    "print(\"Cosine similarity result\")\n",
    "print(compare_cosine_similarity(bbw_1, comp_1))\n",
    "print(compare_cosine_similarity(bbw_1, comp_2))\n",
    "\n",
    "# names-matcher result\n",
    "print(\"Names matcher result\")\n",
    "print(NamesMatcher()([bbw_1], [comp_1])[1][0])\n",
    "print(NamesMatcher()([bbw_1], [comp_2])[1][0])\n",
    "\n",
    "# fuzzy wuzzy result \n",
    "print(\"Fuzzy ratio result\")\n",
    "print(fuzz.ratio(bbw_1, comp_1)/100)\n",
    "print(fuzz.ratio(bbw_1, comp_2)/100)\n",
    "\n",
    "# == we see that there's a difference between results from the 3 algos == #\n",
    "# upon further research, we find that fuzz.ratio() is case sensitive\n",
    "\n",
    "# fuzzy wuzzy result\n",
    "print(\"Fuzzy ratio result - considering case sensitivity\")\n",
    "print(fuzz.ratio(bbw_1.lower(), comp_1.lower())/100)\n",
    "print(fuzz.ratio(bbw_1.lower(), comp_2.lower())/100)\n",
    "\n",
    "# fuzzy wuzzy result - token set ratio result\n",
    "print(\"Fuzzy token set ratio result - token set is not case sensitive\")\n",
    "print(fuzz.token_set_ratio(bbw_1, comp_1)/100)\n",
    "print(fuzz.token_set_ratio(bbw_1, comp_2)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEGATIVE SAMPLE\n",
    "# sample 2 - products that are NOT supposed to be matched - with extra tests this time\n",
    "bbw_2 = \"BATASIOLO MOSCATO SPUNANTE NV\"\n",
    "comp_3 = \"Prunotto Moscato 2020\"\n",
    "comp_4 = \"BATASIOLO MOSCATO D’ASTI DOCG BOSC DLA REI 2019\"\n",
    "comp_5 = \"BATASIOLO MOSCATO D’ASTI DOCG BOSC DLA REI\" # searching without the vintage (year)\n",
    "comp_6 = \"BENI DI BATASIOLO MOSCATO D'ASTI DOCG BOSC D'LA REI 2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity result\n",
      "0.2886751345948129\n",
      "0.35355339059327373\n",
      "0.3779644730092272\n",
      "0.31622776601683794\n",
      "Fuzzy ratio result\n",
      "0.44\n",
      "0.58\n",
      "0.59\n",
      "0.52\n",
      "Fuzzy token set ratio result\n",
      "0.52\n",
      "0.74\n",
      "0.74\n",
      "0.74\n",
      "Names matcher result\n",
      "0.85\n",
      "0.826086956521739\n",
      "0.8636363636363636\n",
      "0.875\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity result\n",
    "print(\"Cosine similarity result\")\n",
    "print(compare_cosine_similarity(bbw_2, comp_3))\n",
    "print(compare_cosine_similarity(bbw_2, comp_4))\n",
    "print(compare_cosine_similarity(bbw_2, comp_5))\n",
    "print(compare_cosine_similarity(bbw_2, comp_6))\n",
    "\n",
    "# fuzzy wuzzy result \n",
    "print(\"Fuzzy ratio result\")\n",
    "print(fuzz.ratio(bbw_2.lower(), comp_3.lower())/100)\n",
    "print(fuzz.ratio(bbw_2.lower(), comp_4.lower())/100)\n",
    "print(fuzz.ratio(bbw_2.lower(), comp_5.lower())/100)\n",
    "print(fuzz.ratio(bbw_2.lower(), comp_6.lower())/100)\n",
    "\n",
    "# fuzzy wuzzy result - token set ratio result\n",
    "print(\"Fuzzy token set ratio result\")\n",
    "print(fuzz.token_set_ratio(bbw_2, comp_3)/100)\n",
    "print(fuzz.token_set_ratio(bbw_2, comp_4)/100)\n",
    "print(fuzz.token_set_ratio(bbw_2, comp_5)/100)\n",
    "print(fuzz.token_set_ratio(bbw_2, comp_6)/100)\n",
    "\n",
    "# names matcher result\n",
    "print(\"Names matcher result\")\n",
    "print(NamesMatcher()([bbw_2], [comp_3])[1][0])\n",
    "print(NamesMatcher()([bbw_2], [comp_4])[1][0])\n",
    "print(NamesMatcher()([bbw_2], [comp_5])[1][0])\n",
    "print(NamesMatcher()([bbw_2], [comp_6])[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- names matcher seems to be very lenient and inaccurate when matching products that are not supposed to be matched\n",
    "- on the other hand, cosine similarity score seems to be compressed. relatively small spread between the scores of positive vs negative samples\n",
    "- token set ratio is also quite lenient for negative samples as it is a more flexible approach than purely using Levenshtein distance\n",
    "\n",
    "#### More about the algorithms used\n",
    "- fuzz.ratio: using Levenshtein distance (number of single character insertions, deletions or substitutions required to change one string into another)\n",
    "- cosine similarity: n-gram matching\n",
    "- names matching: similarity metric is max(ratio, token_set_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case 1: Match BBW Products with BBW Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products df shape: (2355, 3)\n",
      "Orders df shape: (19467, 13)\n",
      "Merged df shape: (19467, 16)\n"
     ]
    }
   ],
   "source": [
    "# === get product & order data === #\n",
    "products_df = pd.read_csv('../datasets/products.csv')\n",
    "products_df = products_df[['product_name','shopify_product_id','product_type']]\n",
    "\n",
    "products_df[\"product_name\"].value_counts() # we see that there are duplicates\n",
    "products_df = products_df.drop_duplicates(subset=['product_name'])\n",
    "print('Products df shape: ' + str(products_df.shape))\n",
    "\n",
    "orders_df = pd.read_csv('../datasets/cleaned_orders.csv')\n",
    "print('Orders df shape: ' + str(orders_df.shape))\n",
    "\n",
    "# === merge product & order data to find exact matches of product name === #\n",
    "merged = orders_df.merge(products_df, left_on='item_id', right_on=\"product_name\", how=\"left\")\n",
    "print('Merged df shape: ' + str(merged.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_cleaned df shape: (10444, 16)\n",
      "dropped df shape: (9023, 16)\n"
     ]
    }
   ],
   "source": [
    "# merged_cleaned: contains all the orders that have exact matches to product name from product data\n",
    "merged_cleaned = merged.dropna(subset=['shopify_product_id'])\n",
    "print('merged_cleaned df shape: ' + str(merged_cleaned.shape))\n",
    "\n",
    "# dropped: contains all the orders that don't have exact matches\n",
    "dropped = merged[merged['shopify_product_id'].isna()]\n",
    "print('dropped df shape: ' + str(dropped.shape))\n",
    "\n",
    "# === to check which order items have been dropped === #\n",
    "# values = dropped['item_id'].value_counts()\n",
    "# values.to_csv('datasets/items_dropped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products dictionary, key: product_name, values: { shopify_product_id, product_type } \n",
    "products_dict = products_df.set_index('product_name').to_dict('index') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_dropped = dropped.copy() # orders with no exact product name matches\n",
    "\n",
    "for index, row in dropped.iterrows():\n",
    "    # preliminary checks to reduce comp power -> check if substring inside pdt dict keys\n",
    "    volume_pattern = r'(- \\d+\\s*(ml|ML|l|L))'  # Match digits followed by \"ml,\", \"ML\", \"L,\" or \"l\"\n",
    "    year_pattern = r'(\\b\\d{4}\\b)'  # Match year/vintage\n",
    "    # Remove volume & year patterns from the string\n",
    "    string = re.sub(volume_pattern, '', row['item_id'], flags=re.IGNORECASE) # case-insensitive\n",
    "    string = re.sub(year_pattern, '', string)\n",
    "    res = [key for key in products_dict.keys() if string in key]\n",
    "\n",
    "    fuzzthreshold = 70 # threshold for fuzzy score - currently an arbitrary number\n",
    "\n",
    "    if len(res) == 0: # if the new string gives no matches, do fuzzy score with pdt dict\n",
    "        max_score = 0\n",
    "        best_match = \"\"\n",
    "        for key in products_dict.keys():\n",
    "            if fuzz.ratio(row['item_id'], key) > max_score and max_score >= fuzzthreshold:\n",
    "                best_match = key\n",
    "                max_score = fuzz.ratio(row['item_id'], key)\n",
    "\n",
    "    if len(res) >= 1:\n",
    "        scores = []\n",
    "        for pdt in res: # find similarity score based on ORIGINAL pdt name from orders data\n",
    "            scores.append(fuzz.ratio(row['item_id'], pdt))\n",
    "        max_score = max(scores) # find max score - best match\n",
    "        best_match = res[scores.index(max_score)]\n",
    "\n",
    "    if max_score >= fuzzthreshold:\n",
    "        copied_dropped.at[index, 'product_name'] = best_match\n",
    "        copied_dropped.at[index, 'shopify_product_id'] = products_dict[best_match]['shopify_product_id']\n",
    "        copied_dropped.at[index, 'product_type'] = products_dict[best_match]['product_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_cleaned2 df shape: (3744, 16)\n",
      "final df shape: (14188, 16)\n"
     ]
    }
   ],
   "source": [
    "# merged_cleaned2: contains orders that have good-enough product name matches\n",
    "merged_cleaned2 = copied_dropped.dropna(subset=['shopify_product_id'])\n",
    "print('merged_cleaned2 df shape: ' + str(merged_cleaned2.shape))\n",
    "\n",
    "# final: all matched products from 1st & 2nd round of matching\n",
    "final = pd.concat([merged_cleaned, merged_cleaned2], ignore_index=True)\n",
    "print('final df shape: ' + str(final.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('../datasets/matched_orders.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case 2: Match BBW Products with Competitors' Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
